{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03302f9a-2ff4-4e36-8539-0990010e0435",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy import stats\n",
    "import numpy.ma as ma\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "#import mplotutils as mpu\n",
    "#import cf_units\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import glob\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d4fc977-0856-46e8-b064-66447e3af2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "## functions to calculate trends, \n",
    "\n",
    "def linregress_grid(df,df_time,start,end):\n",
    "    x,y=np.meshgrid(np.arange(36),np.arange(72))\n",
    "    slope=np.full([36,72],np.nan)\n",
    "    i_start=np.where(df_time==start)[0][0]\n",
    "    i_end=np.where(df_time==end)[0][0]\n",
    "    \n",
    "    for i_x, i_y in zip(x.flatten(),y.flatten()):\n",
    "        if not np.all(np.isnan(df[i_start:i_end+1,i_x,i_y])):\n",
    "            #print(np.all(df[i_start:i_end+1,i_x,i_y]==np.nan),df[i_start:i_end+1,i_x,i_y])\n",
    "            slope[i_x,i_y]=100*stats.linregress(np.arange(end-start+1)[~np.isnan(df[i_start:i_end+1,i_x,i_y])],\n",
    "                                                df[i_start:i_end+1,i_x,i_y][~np.isnan(df[i_start:i_end+1,i_x,i_y])])[0]\n",
    "    return slope\n",
    "\n",
    "def mean_trend_from_dict(df,df_time,start,end, roll=False):\n",
    "    \n",
    "    print([df[key].shape for key in df.keys()])\n",
    "    all_trends=np.stack([linregress_grid(df[key],df_time,start,end) for key in tqdm(df.keys())])\n",
    "    \n",
    "    if roll:\n",
    "        return np.roll(np.mean(all_trends,axis=0),36,1)\n",
    "    else:\n",
    "        return np.mean(all_trends,axis=0)\n",
    "    \n",
    "def trend_dist_from_dict(df,df_time,start,end, roll=False):\n",
    "    \n",
    "    all_trends=np.stack([linregress_grid(df[key],df_time,start,end) for key in tqdm(df.keys())])\n",
    "    \n",
    "    if roll:\n",
    "        return np.roll(np.quantile(all_trends,[0.05,0.95],axis=0),36,1)\n",
    "    else:\n",
    "        return np.quantile(all_trends,[0.05,0.95],axis=0)\n",
    "    \n",
    "def trend_from_dict(df,df_time,start,end, roll=False):\n",
    "    \n",
    "    all_trends=np.stack([linregress_grid(df[key],df_time,start,end) for key in tqdm(df.keys())])\n",
    "    \n",
    "    if roll:\n",
    "        return np.roll(all_trends,36,1)\n",
    "    else:\n",
    "        return all_trends\n",
    "        \n",
    "            \n",
    "def create_mask(df):\n",
    "    \n",
    "    ##First check that the year is 'valid' i.e. 5 months are non nana\n",
    "    df=df.reshape(-1,12,df.shape[1],df.shape[2])\n",
    "    valid_idx=np.zeros([df.shape[0],36,72])\n",
    "    \n",
    "    for yr_idx in range(df.shape[0]):\n",
    "        valid_idx[yr_idx,:,:]=np.where(np.isnan(df[yr_idx,:,:,:]).sum(axis=0)>6,1,0)\n",
    "        \n",
    "\n",
    "    cutoff=valid_idx.shape[0]%5\n",
    "            \n",
    "    valid_idx=valid_idx[cutoff:,:,:].reshape(5,-1,36,72)\n",
    "    \n",
    "    mask_idx=np.zeros([5,36,72])\n",
    "    \n",
    "    for idx_block in range(5):\n",
    "        mask_idx[idx_block,:,:]=np.where(valid_idx[idx_block,:,:,:].sum(axis=0)>np.floor(0.2*valid_idx.shape[1]),\n",
    "                                                np.nan,1)\n",
    "        \n",
    "    print(valid_idx.shape,np.floor(0.8*valid_idx.shape[1]))\n",
    "    mask_idx=np.prod(mask_idx,axis=0)\n",
    "    \n",
    "    return np.roll(~np.isnan(mask_idx),36,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6b87e3c-8830-4037-869c-787c9b185df3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'glob' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m hadcrut_anom\u001b[38;5;241m=\u001b[39m{}\n\u001b[1;32m      4\u001b[0m dir_var_hn\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/HadCRUT_observations/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 5\u001b[0m obs_name_list\u001b[38;5;241m=\u001b[39m\u001b[38;5;28msorted\u001b[39m(\u001b[43mglob\u001b[49m\u001b[38;5;241m.\u001b[39mglob(dir_var_hn\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHadCRUT.4.6.0.0.anomalies.*.nc\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i,obs_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(obs_name_list): \n\u001b[1;32m      8\u001b[0m     data\u001b[38;5;241m=\u001b[39mxr\u001b[38;5;241m.\u001b[39mopen_mfdataset(obs_name)\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime.year\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mroll(longitude\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m180\u001b[39m, roll_coords\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39msel(year\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mslice\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1869-01-01\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2101-01-01\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'glob' is not defined"
     ]
    }
   ],
   "source": [
    "# read in observations\n",
    "hadcrut_anom={}\n",
    "\n",
    "dir_var_hn='data/HadCRUT_observations/'\n",
    "obs_name_list=sorted(glob.glob(dir_var_hn+'HadCRUT.4.6.0.0.anomalies.*.nc'))\n",
    "\n",
    "for i,obs_name in enumerate(obs_name_list): \n",
    "    data=xr.open_mfdataset(obs_name).groupby('time.year').mean('time').roll(longitude=180, roll_coords=True).sel(year=slice('1869-01-01', '2101-01-01'))\n",
    "    hadcrut_anom[i]=data.temperature_anomaly.values\n",
    "\n",
    "# reference year to calculate trend    \n",
    "ref=1951\n",
    "\n",
    "hadcrut_med=xr.open_mfdataset('data/HadCRUT.4.6.0.0.median.nc')\n",
    "hadcrut_med=hadcrut_med.groupby('time.year').mean('time')#.sel(time=slice('1870-01-01', '2101-01-01'))\n",
    "\n",
    "trend_hadcrut_med={}\n",
    "trend_hadcrut={}\n",
    "\n",
    "# trends for all years in temperature\n",
    "for year_idx in range(2000,2019):\n",
    " \n",
    "    trend_hadcrut_med[year_idx]=linregress_grid(hadcrut_med.sel(year=slice(1870,2021)).roll(longitude=180, roll_coords=True).temperature_anomaly.values,\n",
    "                         hadcrut_med.sel(year=slice(1870,2021)).year.values,ref,year_idx)\n",
    "    trend_hadcrut[year_idx]=trend_dist_from_dict(hadcrut_anom,np.arange(1870,2021),ref,year_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2333ca2-2416-4594-8e80-85f9915d1469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# match [temperature, years] to 5 degree grid, save as file\n",
    "degrees = 5\n",
    "lons = np.linspace(degrees*.5,360-degrees*.5,int(360/degrees))\n",
    "lats = np.linspace(-90+degrees*.5,90-degrees*.5,int(180/degrees))\n",
    "xv, yv = np.meshgrid(lons,lats)\n",
    "\n",
    "temp = list()\n",
    "years = list()\n",
    "lon = list()\n",
    "lat = list()\n",
    "\n",
    "for year in range(2000,2019):\n",
    "    temps = trend_hadcrut_med[year].flatten()\n",
    "    temp.extend(temps)\n",
    "    years.extend([year for i in range(len(temps))])\n",
    "    lon.extend(list(xv.flatten()))\n",
    "    lat.extend(list(yv.flatten()))\n",
    "    \n",
    "    \n",
    "year_temp_grid = pd.DataFrame({\"year\": years, \"temperature\": temp, \"LON_5\":lon,\"LAT_5\":lat})\n",
    "year_temp_grid.to_csv(\"data/grid5_temp_years.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3aa05467-d305-40e5-b211-b2d6e18969ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_avg_with_nan(data, weights):\n",
    "    masked = np.ma.masked_array(data, np.isnan(data))\n",
    "    select = np.invert(np.ma.getmaskarray(masked))\n",
    "    data = data[select]\n",
    "    weights = weights[select]\n",
    "    return np.average(data, weights=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55cb1d3a-e3d3-4487-839c-c21b37a27299",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_64248/2078583284.py:3: DtypeWarning: Columns (36) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  grid_region = pd.read_csv('data/subgrid.csv')\n"
     ]
    }
   ],
   "source": [
    "# match fine subgrid with GDL code on coarse temperature-trend data\n",
    "year_temp_grid = pd.read_csv(\"data/grid5_temp_years.csv\")\n",
    "grid_region = pd.read_csv('data/subgrid.csv')\n",
    "grid_region[\"LON_5\"] = grid_region.LON_5.apply(lambda x: x+360 if x<0 else x)\n",
    "grid_region = grid_region[['LAT_5','LON_5','GDLcode', 'area']]\n",
    "year_temp_grid = year_temp_grid.merge(grid_region, on=[\"LAT_5\", \"LON_5\"], how=\"left\")\n",
    "region_temp = year_temp_grid.groupby([\"GDLcode\",\"year\"])\\\n",
    "              .apply(lambda x: weighted_avg_with_nan(data=x.temperature, weights=x.area))\\\n",
    "              .reset_index().rename(columns={0:'temperature_trend'})\n",
    "# add area data and calculate temp trend for each country\n",
    "region_area = year_temp_grid.groupby([\"GDLcode\",\"year\"])[[\"area\"]].sum().reset_index()\n",
    "region_area[\"CountryGDL\"] = region_area[\"GDLcode\"].apply(lambda x: x[:3]+'t')\n",
    "region_temp = region_temp.merge(region_area, how=\"left\", on=[\"GDLcode\",\"year\"])\n",
    "\n",
    "country_temp = region_temp.groupby([\"CountryGDL\", \"year\"])\\\n",
    "              .apply(lambda x: weighted_avg_with_nan(data=x.temperature_trend, weights=x.area))\\\n",
    "              .reset_index().rename(columns={0:'temperature_trend'})\n",
    "country_area =  region_temp.groupby([\"CountryGDL\", \"year\"])[[\"area\"]].sum().reset_index()\n",
    "country_temp = country_temp.merge(country_area, how=\"left\", on=[\"CountryGDL\",\"year\"]).rename(columns={\"CountryGDL\":\"GDLcode\"})\n",
    "\n",
    "region_country_temp = pd.concat([region_temp.drop(columns=[\"CountryGDL\"]), country_temp])\n",
    "region_country_temp.to_csv(\"data/region_temp_years.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb53e63-3b73-4e72-9c3c-61ee65e7230d",
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "gen=6\n",
    "usr_time_res='ann'\n",
    "period=2016-1891\n",
    "##create datasetsfor allforcing af, historical natural hn and preindustrial control piCONTROL\n",
    "y_af={}\n",
    "y_hn={}\n",
    "y_pi={}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from loading import load_data_single_mod\n",
    "import importlib\n",
    "importlib.reload(sys.modules['loading'])\n",
    "from loading import load_data_single_mod\n",
    "#import glob\n",
    "import sys\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    import warnings\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "\n",
    "gen=6\n",
    "period=2018-1870\n",
    "\n",
    "##create datasetsfor allforcing af, historical natural hn and preindustrial control piCONTROL\n",
    "##models only usable if all-forcing run exists, at least 3 histNat runs exist and length of histNat is same as period under investigation\n",
    "\n",
    "y_af={}\n",
    "y_hn={}\n",
    "y_pi={}\n",
    "\n",
    "time={}\n",
    "\n",
    "models=['MIROC6', 'IPSL-CM6A-LR', 'CanESM5', 'HadGEM3-GC31-LL', 'CNRM-CM6-1', 'GFDL-ESM4', 'ACCESS-ESM1-5', 'BCC-CSM2-MR', 'NorESM2-LM', 'MRI-ESM2-0']\n",
    "\n",
    "usable_models=[]\n",
    "for model in models:\n",
    "    \n",
    "    scenario='historical'\n",
    "\n",
    "    \n",
    "    if gen==6:\n",
    "        member = 'r*i1p1f*'\n",
    "        hist_name = 'hist-nat'\n",
    "    elif gen==5:\n",
    "        hist_name = 'historicalNat'\n",
    "        member = 'r*i1p1'\n",
    "    \n",
    "    len_hn=[]\n",
    "    len_pi=[]\n",
    "    \n",
    " \n",
    "    y_af[model],time[model],srex,srex_names,lon_pc,lat_pc,idx_l,wgt_l=load_data_single_mod(gen,model,scenario,Tanglob_idx=False,Tref_all=True,Tref_start='1961-01-01',Tref_end='1991-01-01')\n",
    "    len_af=[y_af[model][key].shape[0] for key in y_af[model].keys()]\n",
    "    \n",
    "        \n",
    "    dir_var_hn='/net/so4/landclim/snath/DA/data/%s/regridded/'%model\n",
    "    run_name_hn_list=sorted(glob.glob(dir_var_hn+'tas_ann_'+model+'_'+hist_name+'_'+member+'_g05.nc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a981055-96b5-4767-9824-728956432139",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce282d60-ea4a-44cf-b278-a00b6ad562ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "((((seagrass OR mangrove*) AND  (deforest* OR afforest* OR conserv* OR restor* OR manag*) )OR \"blue carbon\")  AND ((carbon OR CO2) NEAR/3 (sequest* OR accumulat* OR storage OR capture)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e66822-ca6f-40f8-a455-0c4143a8b54b",
   "metadata": {},
   "source": [
    "## Some plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e2381d-6989-4a36-9c1e-bf6780581a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "## create mask based on criteria \n",
    "\n",
    "hadcrut_med=xr.open_mfdataset('data/HadCRUT.4.6.0.0.median.nc').sel(time=slice('1951-01-01', '2019-01-01'))\n",
    "mask_1951=create_mask(hadcrut_med.temperature_anomaly.values)\n",
    "\n",
    "\n",
    "##Example plots of trends\n",
    "n_col = 2\n",
    "n_row = 3\n",
    "\n",
    "fs_title=16\n",
    "\n",
    "fig=plt.figure(figsize=(n_col*13, n_row * 11))\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "plt.rcParams.update({'mathtext.default':'regular'}) \n",
    "plt.rcParams.update({'mathtext.default':'it'}) \n",
    "\n",
    "\n",
    "grid = plt.GridSpec(n_row*3, n_col*9+3, wspace=1, hspace=0) # create a grid for the subplots #0.12\n",
    "\n",
    "props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "lons=hadcrut_med.longitude.values\n",
    "lats=hadcrut_med.latitude.values\n",
    "\n",
    "i=0\n",
    "for ref in [1951]:\n",
    "    \n",
    "    i_y=0\n",
    "\n",
    "    ax = plt.subplot(grid[i+1:i+2,i_y*15:i_y*15+15], projection=ccrs.PlateCarree(central_longitude=180))\n",
    "\n",
    "    i_y+=1\n",
    "    i+=1\n",
    "    \n",
    "    y_ma = np.zeros(mask_1951.shape)\n",
    "    y_ma = ma.masked_array(y_ma, mask=mask_1951==False)\n",
    "    y_ma[mask_1951]=trend_hadcrut_med[2000][mask_1951]\n",
    "\n",
    "    ax.coastlines()\n",
    "    mesh_1=ax.pcolormesh(lons, lats, y_ma, transform=ccrs.PlateCarree(central_longitude=180), cmap=plt.cm.get_cmap('coolwarm',14),vmin=-5,vmax=5,rasterized=True)\n",
    "    ax.set_title(\"HadCRUT4 %i-2000\"%(ref),y=1.02,fontsize=12)\n",
    "    cmap_mesh=mesh_1.get_cmap()\n",
    "    cmap_mesh.set_bad('gray')\n",
    "    mesh_1.set_cmap(cmap_mesh)\n",
    "    \n",
    "    ax = plt.subplot(grid[i-(i%2)+1:i-(i%2)+2,i_y*15:i_y*15+15], projection=ccrs.PlateCarree(central_longitude=180))\n",
    "    i_y+=1\n",
    "    \n",
    "    i+=1\n",
    "    \n",
    "    ax.coastlines()\n",
    "    mesh_1=ax.pcolormesh(lons, lats, trend_hadcrut_med[2018], transform=ccrs.PlateCarree(central_longitude=180), cmap=plt.cm.get_cmap('coolwarm',14),vmin=-5,vmax=5,rasterized=True)\n",
    "    ax.set_title(\"HadCRUT4 %i-2018\"%(ref),y=1.02,fontsize=12)\n",
    "    cmap_mesh=mesh_1.get_cmap()\n",
    "    cmap_mesh.set_bad('gray')\n",
    "    mesh_1.set_cmap(cmap_mesh)\n",
    "\n",
    "    \n",
    "axcbar = plt.subplot(grid[i-(i%2):i-(i%2)+1,5:25])\n",
    "cbar=plt.colorbar(mesh_1,orientation='horizontal',fraction=0.4,aspect=45)\n",
    "cbar.set_label('Temperature Trends °C/Century')  \n",
    "plt.axis('off')   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e61b1b-cb3e-4133-984e-fde042c6ca8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gif for grid\n",
    "\n",
    "from cartopy import crs as ccrs\n",
    "import cartopy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import pandas as pd\n",
    "import imageio\n",
    "\n",
    "def temp_trend_grid(year, grid_df):\n",
    "    df = grid_df.loc[grid_df.year==year]\n",
    "    fig = plt.figure(dpi=150, figsize=(7,4.5))\n",
    "\n",
    "    ax = plt.subplot(projection=ccrs.EqualEarth())\n",
    "\n",
    "    ax.coastlines(lw=0.1)\n",
    "\n",
    "    n = np.array(df.temperature).reshape(len(df.LAT_5.unique()),len(df.LON_5.unique()))\n",
    "\n",
    "    mesh = ax.pcolormesh(\n",
    "        df.LON_5.unique(),\n",
    "        df.LAT_5.unique(),\n",
    "        n,\n",
    "        alpha=1,\n",
    "        transform=ccrs.PlateCarree(),\n",
    "        norm = mpl.colors.Normalize(vmin=-5,vmax=5),\n",
    "        cmap=\"RdBu_r\"\n",
    "    )\n",
    "\n",
    "    cbar = plt.colorbar(mesh, orientation=\"horizontal\",\n",
    "                       fraction=0.046, pad=0.04)\n",
    "    cbar.set_label('Temperature difference compared to 1951')\n",
    "\n",
    "    ax.set_title(f'Temperature Trend - Year {year}')\n",
    "    fig.savefig(f\"figures/grid5_temptrend1951_year{year}.png\")\n",
    "    plt.close()\n",
    "    \n",
    "    \n",
    "grid_df = pd.read_csv(\"data/grid5_temp_years.csv\")\n",
    "for i in range(2000,2019):\n",
    "    temp_trend_grid(i, grid_df)\n",
    "\n",
    "filenames = [f\"figures/grid5_temptrend1951_year{year}.png\" for year in range(2000,2019)]\n",
    "images = []\n",
    "for filename in filenames:\n",
    "    images.append(imageio.imread(filename))\n",
    "imageio.mimsave('grid5_temperature.gif', images, duration=0.5 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e85298-08ad-4633-9a48-8d9804fb7389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gif for region\n",
    "import geoplot\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import geopandas\n",
    "from datetime import datetime\n",
    "\n",
    "def plot_region_temp(year, dat):\n",
    "    df = dat.loc[dat.year==year]\n",
    "    \n",
    "    fig, ax = plt.subplots(dpi=150, figsize=(7,4.5))\n",
    "    ax = plt.subplot(projection=ccrs.EqualEarth())\n",
    "\n",
    "    ax.coastlines(lw=0.1)\n",
    "\n",
    "    cmap = mpl.cm.get_cmap('RdBu_r')\n",
    "    norm = mpl.colors.Normalize(vmin=-5,vmax=5)\n",
    "\n",
    "    #ax.add_geometries(merged.geometry, lw=0.1, linestyle=':',crs=ccrs.EqualEarth(),color=colors)\n",
    "    for i, row in df.iterrows():\n",
    "\n",
    "        ax.add_geometries(\n",
    "            [row['geometry']],color=cmap(norm(row['temperature_trend'])), \n",
    "            crs=ccrs.PlateCarree(),lw=0.1, linestyle=':',ec=\"black\"\n",
    "        )    \n",
    "    cbar = fig.colorbar(\n",
    "        mpl.cm.ScalarMappable(norm=norm, cmap=cmap), \n",
    "        ax=ax, orientation=\"horizontal\",\n",
    "        fraction=0.046, pad=0.04\n",
    "    )\n",
    "    ax.set_title(f'Temperature Trend - Year {year}')\n",
    "    cbar.set_label('Temperature difference compared to 1951')\n",
    "    fig.savefig(f\"figures/region_temptrend1951_year{year}.png\")\n",
    "    plt.close()\n",
    "\n",
    "gdl_shapes = geopandas.read_file(\"data/GDL Shapefiles V5 11-21.shp\")\n",
    "reg_df = pd.read_csv(\"data/region_temp_years.csv\").merge(gdl_shapes,left_on=\"GDLcode\",right_on=\"gdlcode\").fillna(0)\n",
    "for year in range(2000,2019):\n",
    "    print(year)\n",
    "    current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "    print(\"Current Time =\", current_time)\n",
    "    plot_region_temp(year, reg_df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a61ed5-ed7e-4825-a8f4-e000f6688353",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = [f\"figures/region_temptrend1951_year{year}.png\" for year in range(2000,2018)]\n",
    "images = []\n",
    "for filename in filenames:\n",
    "    images.append(imageio.imread(filename))\n",
    "imageio.mimsave('region_temperature.gif', images, duration=0.5 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdcfbae-7737-41e0-8707-8bda513f1efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cartopy import crs as ccrs\n",
    "import cartopy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(dpi=150, figsize=(7,4.5))\n",
    "\n",
    "ax = plt.subplot(projection=ccrs.EqualEarth())\n",
    "\n",
    "ax.coastlines(lw=0.1)\n",
    "\n",
    "n = np.array(grid_df.temp).reshape(len(grid_df.LAT.unique()),len(grid_df.LON.unique()))\n",
    "\n",
    "mesh = ax.pcolormesh(\n",
    "    grid_df.LON.unique(),\n",
    "    grid_df.LAT.unique(),\n",
    "    n,\n",
    "    alpha=1,\n",
    "    transform=ccrs.PlateCarree(),\n",
    "    norm = mpl.colors.Normalize(vmin=-5,vmax=5),\n",
    "    cmap=\"RdBu_r\"\n",
    ")\n",
    "\n",
    "cbar = plt.colorbar(mesh, orientation=\"horizontal\",\n",
    "                   fraction=0.046, pad=0.04)\n",
    "cbar.set_label('area ($km^2$)')\n",
    "\n",
    "ax.set_title('2.5 degree grid cells')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "climate",
   "language": "python",
   "name": "climate"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
